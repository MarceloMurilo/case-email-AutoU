# utils_semantic.py
"""
Classifica√ß√£o Sem√¢ntica usando MiniLM-L6-v2
Com detec√ß√£o de nega√ß√£o e ajustes inteligentes

NOTA: Modo sem√¢ntico dispon√≠vel apenas em localhost (biblioteca muito pesada para Render).
Faz fallback para modo NLP quando sentence-transformers n√£o est√° dispon√≠vel ou em produ√ß√£o.
"""
import os

# Verificar se est√° em localhost (desenvolvimento)
IS_LOCALHOST = os.getenv("RENDER") is None  # Render define vari√°vel RENDER em produ√ß√£o

try:
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    import numpy as np
    
    # Carregar modelo MiniLM apenas se estiver em localhost
    if IS_LOCALHOST:
        model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
        SEMANTIC_AVAILABLE = True
    else:
        SEMANTIC_AVAILABLE = False
        model = None
except ImportError:
    # Fallback: usar NLP quando sentence-transformers n√£o est√° dispon√≠vel
    SEMANTIC_AVAILABLE = False
    model = None

# Importar NLP para fallback
if not SEMANTIC_AVAILABLE:
    from utils_nlp import classify_email_nlp, generate_reply_nlp


# üö´ Frases que anulam produtividade mesmo se o texto parecer t√©cnico
NEGACOES = [
    "n√£o precisa", "nao precisa",
    "n√£o √© necess√°rio", "nao e necessario",
    "n√£o necessita", "nao necessita",
    "pode desconsiderar", "podem desconsiderar",
    "j√° foi resolvido", "ja foi resolvido",
    "tudo certo por aqui",
    "nenhuma a√ß√£o", "nenhuma acao",
    "n√£o exige retorno", "nao exige retorno",
    "apenas registro", "s√≥ registro",
    "somente para informar", "apenas para informar"
]


# üìå Refer√™ncias ampliadas
REFERENCIAS = {
    "produtivo": [
        "protocolo",
        "n√∫mero de chamado",
        "segue em anexo",
        "curr√≠culo",
        "documento",
        "pedido",
        "solicita√ß√£o",
        "informa√ß√µes",
        "atualiza√ß√£o",
        "necess√°rio verificar",
        "urgente",
        "preciso de ajuda",
        "pode verificar",
        "erro no sistema",
        "chamado em aberto"
    ],
    "improdutivo": [
        "feliz natal",
        "parab√©ns",
        "obrigado",
        "mensagem social",
        "bom dia",
        "boa tarde",
        "felicidades",
        "bom final de semana",
        "apenas informando",
        "sem necessidade de retorno",
        "n√£o precisa fazer nada",
        "tudo resolvido internamente",
        "podem ignorar"
    ]
}

# Criar embeddings de refer√™ncia s√≥ 1 vez (se dispon√≠vel e em localhost)
if SEMANTIC_AVAILABLE and model is not None:
    ref_embeddings = {
        cat: model.encode(frases)
        for cat, frases in REFERENCIAS.items()
    }
else:
    ref_embeddings = {}


def classify_email_semantic(text: str) -> dict:
    """
    Classifica√ß√£o usando MiniLM com heur√≠sticas inteligentes.
    Faz fallback para NLP se sentence-transformers n√£o estiver dispon√≠vel.
    """
    if not SEMANTIC_AVAILABLE:
        # Fallback para NLP quando sem√¢ntico n√£o est√° dispon√≠vel
        resultado = classify_email_nlp(text)
        return {
            "categoria": resultado["categoria"],
            "analise_semantica": {
                "similaridade_produtivo": 0,
                "similaridade_improdutivo": 0,
                "diferenca": 0,
                "nota": "Modo sem√¢ntico n√£o dispon√≠vel (usando NLP como fallback)"
            },
            "confianca": f"{resultado['confianca']}%"
        }
    
    texto_lower = text.lower()

    # 1) üîç Regra de nega√ß√£o ‚Äî domina tudo
    for n in NEGACOES:
        if n in texto_lower:
            return {
                "categoria": "IMPRODUTIVO",
                "analise_semantica": {
                    "similaridade_produtivo": 0,
                    "similaridade_improdutivo": 100,
                    "diferenca": 100
                },
                "confianca": "AUTO (detec√ß√£o de nega√ß√£o)"
            }

    # 2) üîç Embeddings sem√¢nticos normais
    texto_embedding = model.encode([text])[0]

    sim_prod = np.mean(cosine_similarity([texto_embedding], ref_embeddings["produtivo"])[0])
    sim_improd = np.mean(cosine_similarity([texto_embedding], ref_embeddings["improdutivo"])[0])

    # 3) üîç Soft decision
    if sim_prod >= sim_improd:
        categoria = "PRODUTIVO"
    else:
        categoria = "IMPRODUTIVO"

    return {
        "categoria": categoria,
        "analise_semantica": {
            "similaridade_produtivo": round(float(sim_prod * 100), 2),
            "similaridade_improdutivo": round(float(sim_improd * 100), 2),
            "diferenca": round(float(abs(sim_prod - sim_improd) * 100), 2)
        },
        "confianca": f"{round(float(abs(sim_prod - sim_improd) * 100), 1)}%"
    }


def generate_reply_semantic(text: str, categoria: str) -> str:
    """
    Resposta template baseada na categoria sem√¢ntica
    Faz fallback para NLP se sentence-transformers n√£o estiver dispon√≠vel.
    """
    if not SEMANTIC_AVAILABLE:
        # Fallback para NLP quando sem√¢ntico n√£o est√° dispon√≠vel
        return generate_reply_nlp(text, categoria)
    
    if categoria == "PRODUTIVO":
        return """Ol√°!

Recebemos sua solicita√ß√£o e nossa equipe j√° est√° analisando.
Retornaremos com uma resposta em breve.

Atenciosamente,
Equipe de Atendimento"""
    else:
        return """Ol√°!

Muito obrigado pela sua mensagem!
Ficamos felizes com o contato.

Atenciosamente,
Equipe"""
